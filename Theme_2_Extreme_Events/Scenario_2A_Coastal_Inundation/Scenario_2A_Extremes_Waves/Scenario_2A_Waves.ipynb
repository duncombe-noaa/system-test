{
 "metadata": {
  "name": "",
  "signature": "sha256:9bbb4513107d3f0231f5ea4fb9970aa5615d93bc89eabae7981a4af7dbb6aded"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "># IOOS System Test: [Extreme Events Theme:](https://github.com/ioos/system-test/wiki/Development-of-Test-Themes#theme-2-extreme-events) Inundation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Can we estimate the return period of a wave height by obtaining long term wave height records from observed and modelled datasets?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "import required libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from pylab import *\n",
      "import sys\n",
      "import csv\n",
      "import json\n",
      "from scipy.stats import genextreme\n",
      "import scipy.stats as ss\n",
      "import numpy as np\n",
      "\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from owslib import fes\n",
      "import random\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "import datetime as dt\n",
      "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
      "import cStringIO\n",
      "import iris\n",
      "import urllib2\n",
      "import parser\n",
      "from lxml import etree       #TODO suggest using bs4 instead for ease of access to XML objects\n",
      "\n",
      "#generated for csw interface\n",
      "#from date_range_formatter import dateRange  #date formatter (R.Signell)\n",
      "import requests              #required for the processing of requests\n",
      "from utilities import * \n",
      "\n",
      "from IPython.display import HTML\n",
      "import folium #required for leaflet mapping\n",
      "import calendar #used to get number of days in a month and year"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "some functions from [Rich Signell Notebook](http://nbviewer.ipython.org/github/rsignell-usgs/notebook/blob/fef9438303b49a923024892db1ef3115e34d8271/CSW/IOOS_inundation.ipynb)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Speficy Temporal and Spatial conditions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bounding box of interest,[bottom right[lat,lon], top left[lat,lon]]\n",
      "bounding_box_type = \"box\" \n",
      "bounding_box = [[-152.00,59.25],[-150.60,60.00]]\n",
      "\n",
      "#temporal range\n",
      "start_date = dt.datetime(1991,5,1).strftime('%Y-%m-%d %H:00')\n",
      "end_date = dt.datetime(2014,5,10).strftime('%Y-%m-%d %H:00')\n",
      "time_date_range = [start_date,end_date]  #start_date_end_date\n",
      "\n",
      "print start_date,'to',end_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1991-05-01 00:00 to 2014-05-10 00:00\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw' # NGDC Geoportal\n",
      "csw = CatalogueServiceWeb(endpoint,timeout=60)\n",
      "\n",
      "for oper in csw.operations:\n",
      "    if oper.name == 'GetRecords':\n",
      "        #print '\\nISO Queryables:\\n',oper.constraints['SupportedISOQueryables']['values']\n",
      "        pass\n",
      "        \n",
      "#put the names in a dict for ease of access \n",
      "data_dict = {}\n",
      "data_dict[\"waves\"] = {\"names\":['sea_surface_wave_significant_height','significant_wave_height'], \n",
      "                      \"sos_name\":[\"waves\"]}      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dateRange(start_date='1900-01-01',stop_date='2100-01-01',constraint='overlaps'):\n",
      "    if constraint == 'overlaps':\n",
      "        start = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=stop_date)\n",
      "        stop = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=start_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=stop_date)\n",
      "    return start,stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert User Input into FES filters\n",
      "start,stop = dateRange(start_date,end_date)\n",
      "box = []\n",
      "box.append(bounding_box[0][0])\n",
      "box.append(bounding_box[0][1])\n",
      "box.append(bounding_box[1][0])\n",
      "box.append(bounding_box[1][1])\n",
      "bbox = fes.BBox(box)\n",
      "\n",
      "#use the search name to create search filter\n",
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                    escapeChar='\\\\',wildCard='*',singleChar='?') for val in data_dict[\"waves\"][\"names\"]])\n",
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                        escapeChar='\\\\',wildCard='*',singleChar='?')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter_list = [fes.And([ bbox, start, stop, or_filt, not_filt]) ]\n",
      "# connect to CSW, explore it's properties\n",
      "# try request using multiple filters \"and\" syntax: [[filter1,filter2]]\n",
      "csw.getrecords2(constraints=filter_list,maxrecords=1000,esn='full')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def service_urls(records,service_string='urn:x-esri:specification:ServiceType:odp:url'):\n",
      "    \"\"\"\n",
      "    extract service_urls of a specific type (DAP, SOS) from records\n",
      "    \"\"\"\n",
      "    urls=[]\n",
      "    for key,rec in records.iteritems():        \n",
      "        #create a generator object, and iterate through it until the match is found\n",
      "        #if not found, gets the default value (here \"none\")\n",
      "        url = next((d['url'] for d in rec.references if d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print records that are available\n",
      "print \"number of datasets available: \",len(csw.records.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of datasets available:  46\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print all the records (should you want too)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(csw.records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "inundation_tropical.VIMS_SELFE.Hurricane_Ike_2D_final_run_wave_only\n",
        "inundation_tropical.VIMS_SELFE.Hurricane_Ike_2D_final_run_with_waves\n",
        "inundation_tropical.VIMS_SELFE.Hurricane_Ike_3D_final_run_with_waves\n",
        "inundation_tropical.VIMS_SELFE.Hurricane_Rita_2D_final_run_waves_only\n",
        "inundation_tropical.VIMS_SELFE.Hurricane_Rita_2D_final_run_with_waves\n",
        "inundation_tropical.VIMS_SELFE.Hurricane_Rita_3D_final_run_with_waves\n",
        "CDIP_Archive/100p1/100p1_historic.nc\n",
        "coawst_4/use/fmrc/coawst_4_use_best.ncd\n",
        "CDIP_Archive/091p1/091p1_d14.nc\n",
        "CDIP_Archive/126p1/126p1_d02.nc\n",
        "CDIP_Archive/101p1/101p1_d01.nc\n",
        "CDIP_Archive/114p1/114p1_d04.nc\n",
        "CDIP_Archive/067p1/067p1_d16.nc\n",
        "CDIP_Archive/028p1/028p1_d03.nc\n",
        "CDIP_Archive/096p1/096p1_d09.nc\n",
        "CDIP_Archive/095p1/095p1_d06.nc\n",
        "CDIP_Archive/118p1/118p1_d01.nc\n",
        "CDIP_Archive/095p1/095p1_d05.nc\n",
        "CDIP_Archive/098p1/098p1_d08.nc\n",
        "CDIP_Archive/100p1/100p1_d03.nc\n",
        "CDIP_Archive/045p1/045p1_d12.nc\n",
        "CDIP_Archive/098p1/098p1_d12.nc\n",
        "CDIP_Archive/029p1/029p1_d06.nc\n",
        "CDIP_Archive/067p1/067p1_historic.nc\n",
        "CDIP_Archive/098p1/098p1_d06.nc\n",
        "CDIP_Archive/111p1/111p1_d02.nc\n",
        "CDIP_Archive/028p1/028p1_d08.nc\n",
        "CDIP_Archive/100p1/100p1_d05.nc\n",
        "CDIP_Archive/102p1/102p1_d01.nc\n",
        "CDIP_Archive/029p1/029p1_historic.nc\n",
        "CDIP_Archive/071p1/071p1_d07.nc\n",
        "CDIP_Archive/029p1/029p1_d13.nc\n",
        "CDIP_Archive/071p1/071p1_historic.nc\n",
        "CDIP_Archive/100p1/100p1_d02.nc\n",
        "CDIP_Archive/094p1/094p1_historic.nc\n",
        "CDIP_Archive/071p1/071p1_d08.nc\n",
        "CDIP_Archive/096p1/096p1_historic.nc\n",
        "CDIP_Archive/036p1/036p1_d32.nc\n",
        "CDIP_Archive/094p1/094p1_d07.nc\n",
        "CDIP_Archive/094p1/094p1_d01.nc\n",
        "CDIP_Archive/096p1/096p1_d08.nc\n",
        "ww3_global\n",
        "CDIP_Archive/092p1/092p1_d12.nc\n",
        "CDIP_Archive/028p1/028p1_d07.nc\n",
        "CDIP_Archive/128p1/128p1_d07.nc\n",
        "CDIP_Archive/094p1/094p1_d06.nc\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dap URLS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:odp:url')\n",
      "#remove duplicates and organize\n",
      "dap_urls = sorted(set(dap_urls))\n",
      "print \"Total DAP:\",len(dap_urls)\n",
      "#print the first 5...\n",
      "print \"\\n\".join(dap_urls[:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total DAP: 46\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_wave_only\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_with_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_3D_final_run_with_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Rita_2D_final_run_waves_only\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Rita_2D_final_run_with_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Rita_3D_final_run_with_waves\n",
        "http://geoport.whoi.edu/thredds/dodsC/coawst_4/use/fmrc/coawst_4_use_best.ncd\n",
        "http://oos.soest.hawaii.edu/thredds/dodsC/hioos/model/wav/ww3/WaveWatch_III_Global_Wave_Model_best.ncd\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/028p1/028p1_d03.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/028p1/028p1_d07.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/028p1/028p1_d08.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/029p1/029p1_d06.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/029p1/029p1_d13.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/029p1/029p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/036p1/036p1_d32.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/045p1/045p1_d12.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/067p1/067p1_d16.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/067p1/067p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/071p1/071p1_d07.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/071p1/071p1_d08.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/071p1/071p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/091p1/091p1_d14.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/092p1/092p1_d12.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/094p1/094p1_d01.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/094p1/094p1_d06.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/094p1/094p1_d07.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/094p1/094p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/095p1/095p1_d05.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/095p1/095p1_d06.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/096p1/096p1_d08.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/096p1/096p1_d09.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/096p1/096p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/098p1/098p1_d06.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/098p1/098p1_d08.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/098p1/098p1_d12.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/100p1/100p1_d02.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/100p1/100p1_d03.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/100p1/100p1_d05.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/100p1/100p1_historic.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/101p1/101p1_d01.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/102p1/102p1_d01.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/111p1/111p1_d02.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/114p1/114p1_d04.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/118p1/118p1_d01.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/126p1/126p1_d02.nc\n",
        "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/128p1/128p1_d07.nc\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SOS URLs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### TODO: Fix waves not being found in catalog"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:sos:url')\n",
      "#remove duplicates and organize\n",
      "if len(sos_urls) ==0:\n",
      "    sos_urls.append(\"http://sdf.ndbc.noaa.gov/sos/server.php\")  #?request=GetCapabilities&service=SOS\n",
      "\n",
      "sos_urls = sorted(set(sos_urls))\n",
      "print \"Total SOS:\",len(sos_urls)\n",
      "print \"\\n\".join(sos_urls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total SOS: 38\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/028p1/028p1_d03.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/028p1/028p1_d07.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/028p1/028p1_d08.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/029p1/029p1_d06.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/029p1/029p1_d13.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/029p1/029p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/036p1/036p1_d32.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/045p1/045p1_d12.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/067p1/067p1_d16.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/067p1/067p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/071p1/071p1_d07.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/071p1/071p1_d08.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/071p1/071p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/091p1/091p1_d14.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/092p1/092p1_d12.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/094p1/094p1_d01.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/094p1/094p1_d06.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/094p1/094p1_d07.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/094p1/094p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/095p1/095p1_d05.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/095p1/095p1_d06.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/096p1/096p1_d08.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/096p1/096p1_d09.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/096p1/096p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/098p1/098p1_d06.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/098p1/098p1_d08.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/098p1/098p1_d12.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/100p1/100p1_d02.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/100p1/100p1_d03.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/100p1/100p1_d05.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/100p1/100p1_historic.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/101p1/101p1_d01.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/102p1/102p1_d01.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/111p1/111p1_d02.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/114p1/114p1_d04.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/118p1/118p1_d01.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/126p1/126p1_d02.nc?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/128p1/128p1_d07.nc?service=SOS&version=1.0.0&request=GetCapabilities\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SOS Requirements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the get caps to get station start and get time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_time = dt.datetime.strptime(start_date,'%Y-%m-%d %H:%M')\n",
      "end_time = dt.datetime.strptime(end_date,'%Y-%m-%d %H:%M')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_end = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "\n",
      "collector = NdbcSos()\n",
      "collector.start_time = start_time\n",
      "collector.end_time = end_time\n",
      "collector.variables = data_dict[\"waves\"][\"sos_name\"]\n",
      "collector.server.identification.title\n",
      "print collector.start_time,\":\", collector.end_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1991-05-01 00:00:00+00:00 : 2014-05-10 00:00:00+00:00\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Date: \",iso_start,\" to \", iso_end\n",
      "box_str=','.join(str(e) for e in box)\n",
      "print \"Lat/Lon Box: \",box_str\n",
      "#grab the sos url and use it for the service\n",
      "url=(sos_urls[0]+'?'\n",
      "     'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "     'observedProperty=%s&offering=urn:ioos:network:noaa.nws.ndbc:all&'\n",
      "     'featureOfInterest=BBOX:%s&responseFormat=text/tab-separated-values&eventTime=%s') % (\"waves\",box_str,iso_end)\n",
      "print url\n",
      "r = requests.get(url)\n",
      "data = r.text\n",
      "#get the headers for the cols\n",
      "data = data.split(\"\\n\")\n",
      "headers =  data[0]\n",
      "station_list_dict = dict()\n",
      "#parse the headers so i can create a dict\n",
      "c = 0\n",
      "for h in headers.split(\"\\t\"):\n",
      "    field = h.split(\":\")[0].split(\" \")[0]\n",
      "    station_list_dict[field] = {\"id\":c}\n",
      "    c+=1\n",
      "print \"Num of fields:\", c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Date:  1991-05-01T00:00:00Z  to  2014-05-10T00:00:00Z\n",
        "Lat/Lon Box:  -73.94,40.67,-69.94,42\n",
        "http://thredds.cdip.ucsd.edu/thredds/sos/cdip/archive/028p1/028p1_d03.nc?service=SOS&version=1.0.0&request=GetCapabilities?service=SOS&request=GetObservation&version=1.0.0&observedProperty=waves&offering=urn:ioos:network:noaa.nws.ndbc:all&featureOfInterest=BBOX:-73.94,40.67,-69.94,42&responseFormat=text/tab-separated-values&eventTime=2014-05-10T00:00:00Z\n",
        "Num of fields:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create dict of stations\n",
      "station_list = []\n",
      "for i in range(1,len(data)):\n",
      "    station_info = data[i].split(\"\\t\")\n",
      "    if len(station_info)>1:\n",
      "        station = dict()\n",
      "        for field in station_list_dict.keys():        \n",
      "            col = station_list_dict[field][\"id\"]\n",
      "            if col < len(station_info):\n",
      "                station[field] = station_info[col]     \n",
      "        station[\"type\"] = \"obs\"        \n",
      "        station_list.append(station)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Add wis site infotmation to station list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(station_list)    \n",
      "print float(station_list[0][\"longitude\"])\n",
      "print station_list[0][\"latitude\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-27-c6b4cf066474>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"longitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mstation_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"latitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shapely.geometry import Polygon,Point,LineString\n",
      "import sqlite3 as lite"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the WIS stations that are in the bounding box\n",
      "#generate polygon that matches that of the bounding box\n",
      "poly = Polygon(get_coordinates(bounding_box,bounding_box_type))\n",
      "db = r'/Users/rpsdev/Documents/d3/wis_data/wis_stations.db'\n",
      "print poly\n",
      "try:\n",
      "    conn = lite.connect(db)\n",
      "    cur = conn.cursor()\n",
      "    cur.execute(\"SELECT NAME,LAT,LON FROM station_list\")\n",
      "    records = cur.fetchall()\n",
      "    st_yr =int(collector.start_time.year)\n",
      "    ed_yr =int(collector.end_time.year+1)\n",
      "    min_station_line = -1\n",
      "    min_station_line_set = True\n",
      "    min_station_name = \"\"\n",
      "    station_lat = float(station_list[0][\"latitude\"])\n",
      "    station_lon = float(station_list[0][\"longitude\"])\n",
      "    for r in records:\n",
      "        #name,lat,lon\n",
      "        station_is_contained = poly.contains(Point(float(r[1]),float(r[2])))\n",
      "        #if the station is in the bounds, store it as such\n",
      "        if station_is_contained:\n",
      "            st_name = r[0]\n",
      "            #find the closest station\n",
      "            \n",
      "            line = LineString([(float(r[1]),float(r[2])),(station_lat,station_lon)])\n",
      "            if min_station_line_set:\n",
      "                min_station_line = line.length\n",
      "                min_station_record = r\n",
      "            if line.length < min_station_line:\n",
      "                min_station_record = r\n",
      "                \n",
      "    station = dict()\n",
      "    station[\"latitude\"] = float(min_station_record[1])\n",
      "    station[\"longitude\"] = float(min_station_record[2])\n",
      "    st_name = min_station_record[0]\n",
      "    station[\"long_name\"] = \"WIS:\"+ st_name\n",
      "    station[\"id\"] = st_name\n",
      "    station[\"station_id\"] = st_name\n",
      "    station[\"type\"] = \"model\"\n",
      "    station_data = dict()\n",
      "    for yr in range(st_yr,ed_yr+1):\n",
      "        #get the max value from the monthly max to give yearly max\n",
      "        cur.execute(\"select MAX(hmax) from station_data where name=\"+ str(st_name) +\" and date >=\"+str(yr)+\"01 and date <=\"+str(yr)+\"12\")\n",
      "        yearmax = cur.fetchall()\n",
      "        yearmax = yearmax[0][0]\n",
      "        if yearmax is None:\n",
      "            print \"year \", yr,\" is none\"\n",
      "        else:\n",
      "            station_data[str(yr)] = {\"max\":yearmax,\"num_samples\":0,\"date_string\":\"\"}\n",
      "    station[\"data\"] = station_data\n",
      "    station_list.append(station)\n",
      "except lite.Error:\n",
      "    print \"Error open db.\\n\"\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'lite' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-22-2e2d9c66bc22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mstation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstation_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mstation_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Error open db.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'lite' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Poly((40.67, -73.94) ...)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print out the station name\n",
      "print station_list[0][\"sensor_id\"]\n",
      "print station_list[1]\n",
      "print len(station_list) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "urn:ioos:sensor:wmo:44039::summarywav1\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-7ac40b2125f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print out the station name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mstation_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sensor_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mstation_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_station_long_name(sta):\n",
      "    \"\"\"\n",
      "    get longName for specific station\n",
      "    \"\"\"\n",
      "    url=(sos_urls[0]+'?service=SOS&'\n",
      "        'request=DescribeSensor&version=1.0.0&outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "        'procedure=%s') % sta    \n",
      "    tree = etree.parse(urllib2.urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    longName=root.xpath(\"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\", namespaces={'sml':\"http://www.opengis.net/sensorML/1.0.1\"})\n",
      "    return longName"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sos_data(collector,station_id,sos_name,date_time,field_of_interest):\n",
      "    print \"Station:\",station_id\n",
      "    collector.features = [station_id]\n",
      "    collector.variables = [sos_name] \n",
      "    station_data = dict()\n",
      "    #loop through the years and get the data needed\n",
      "    st_yr =int(collector.start_time.year)\n",
      "    ed_yr =int(collector.end_time.year+1)\n",
      "    #only 31 days are allowed to be requested at once\n",
      "    for year_station in range(st_yr,ed_yr):    \n",
      "        year_station_data = []\n",
      "        date_list = []\n",
      "        for month in range (1,13):\n",
      "                num_days = calendar.monthrange(year_station, month)[1]     \n",
      "\n",
      "                st = dt.datetime(year_station,month,1,0,0,0)\n",
      "                ed = dt.datetime(year_station,month,num_days,23,59,59)\n",
      "\n",
      "                start_time1 = dt.datetime.strptime(str(st),'%Y-%m-%d %H:%M:%S')\n",
      "                end_time1 = dt.datetime.strptime(str(ed),'%Y-%m-%d %H:%M:%S')\n",
      "                \n",
      "                collector.start_time = start_time1\n",
      "                collector.end_time = end_time1\n",
      "                 \n",
      "                try:\n",
      "                    response = collector.raw(responseFormat=\"text/csv\")\n",
      "                    #get the response then get the data\n",
      "                    data =  response.split(\"\\n\")\n",
      "                    first_row = True\n",
      "                    if len(data)>2:\n",
      "                        for d in data:\n",
      "                            d_row = (d.split(\",\"))\n",
      "                            \n",
      "                            if first_row:\n",
      "                                #find the field of interest\n",
      "                                idx1 = [d_row.index(i) for i in d_row if field_of_interest in i][0]\n",
      "                                idx2 = [d_row.index(i) for i in d_row if date_time in i][0]\n",
      "                                first_row = False\n",
      "                            else:  \n",
      "                                if idx1<len(d_row):\n",
      "                                    year_station_data.append(d_row[idx1])\n",
      "                                else:\n",
      "                                    #print idx1,\":\",d_row\n",
      "                                    pass\n",
      "                                    \n",
      "                                if idx2<len(d_row):\n",
      "                                    date_list.append(d_row[idx2])\n",
      "                                else:\n",
      "                                    #print idx2,\":\",d_row\n",
      "                                    pass\n",
      "    \n",
      "                    else:\n",
      "                        #print \"no data...:\",year_station,\":\",month\n",
      "                        pass\n",
      "                except Exception, e: #should only fail if the data is not there\n",
      "                    print e,\":\",year_station,\":\",month\n",
      "\n",
      "        #caluclate the max values   \n",
      "        p = np.array(year_station_data,dtype=np.float)     \n",
      "        if len(p)>2:\n",
      "            station_data[str(year_station)] = {\"max\":np.amax(p),\"num_samples\":len(p),\"date_string\":date_list[np.argmax(p)]}\n",
      "            \n",
      "                    \n",
      "    #reset the collector once complete            \n",
      "    collector.start_time = start_time\n",
      "    collector.end_time = end_time    \n",
      "    return station_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pydap.client import open_url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_model_data(dap_urls,st_lat,st_lon):\n",
      "    # use only data within 0.04 degrees (about 4 km)\n",
      "    max_dist=0.04 \n",
      "    \n",
      "    # use only data where the standard deviation of the time series exceeds 0.01 m (1 cm)\n",
      "    # this eliminates flat line model time series that come from land points that \n",
      "    # should have had missing values.\n",
      "    min_var=0.01\n",
      "    for url in dap_urls:\n",
      "        try:\n",
      "           pass            \n",
      "        except:\n",
      "            pass\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get model data for a station\n",
      "get_model_data(dap_urls,41.138,-72.665)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Embeds the HTML source of the map directly into the IPython notebook.\n",
      "\n",
      "def inline_map(map):   \n",
      "    map._build_map()\n",
      "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 500px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
      "\n",
      "map = folium.Map(location=[bounding_box[0][1], bounding_box[0][0]], zoom_start=6)\n",
      "\n",
      "station_yearly_max = []\n",
      "for s in station_list:\n",
      "    #get the station data from the sos end point\n",
      "    if s[\"type\"] is \"obs\":\n",
      "        #get the long name        \n",
      "        station_num = str(s['station_id']).split(':')[-1]\n",
      "        s[\"station_num\"] = station_num\n",
      "        s[\"long_name\"] = get_station_long_name(s['station_id'])\n",
      "        raw_data = get_sos_data(collector,station_num,\"waves\",\"date_time\",\"sea_surface_wave_significant_height (m)\")    \n",
      "        s[\"data\"] = raw_data\n",
      "    if \"latitude\" in s:\n",
      "        popup_string = '<b>Station:</b><br>'+str(s['station_id']) + \"<br><b>Long Name:</b><br>\"+str(s[\"long_name\"])+\"<br><br>\"+str(s[\"type\"])\n",
      "        map.simple_marker([s[\"latitude\"],s[\"longitude\"]],popup=popup_string)\n",
      "# Create the map and add the bounding box line\n",
      "map.line(get_coordinates(bounding_box,bounding_box_type), line_color='#FF0000', line_weight=5)\n",
      "\n",
      "inline_map(map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import prettyplotlib as ppl\n",
      "fig, ax = plt.subplots(1)\n",
      "\n",
      "# Show the whole color range\n",
      "for s in station_list:\n",
      "    if \"data\" in s:\n",
      "        years = s[\"data\"].keys()\n",
      "        xx = []\n",
      "        yx = []\n",
      "        for y in years:                \n",
      "            val = s[\"data\"][y][\"max\"]            \n",
      "            if val is not None:\n",
      "                try:\n",
      "                    #round to 2dp                    \n",
      "                    val = \"%.2f\" % val\n",
      "                    yx.append(val)\n",
      "                    xx.append(int(y))\n",
      "                except:\n",
      "                    pass\n",
      "                    \n",
      "        #ppl.scatter(ax, xx, yx,alpha=0.8,edgecolor='black',linewidth=0.15 ,label=str(s[\"station_num\"])+\":\"+str(s[\"long_name\"][0]))\n",
      "        ppl.scatter(ax, xx, yx,alpha=0.8,edgecolor='black',linewidth=0.15 ,label=str(s[\"long_name\"]))  \n",
      "     \n",
      "        \n",
      "ax.legend(loc=1)\n",
      "ax.set_title('Annual Max sea surface wave significant height (m) (Observed & Model)')\n",
      "ax.set_xlabel('Year')\n",
      "ax.set_ylabel('sea surface wave significant height (m)')\n",
      "\n",
      "ax.set_xticks(numpy.arange(st_yr,ed_yr,2))\n",
      "fig.set_size_inches(14,8)\n",
      "\n",
      "# Shink current axis by 20%\n",
      "box = ax.get_position()\n",
      "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
      "# Put a legend to the right of the current axis\n",
      "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extreme Value Analysis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annual_max = yx\n",
      "data_levels = []\n",
      "for i in annual_max:\n",
      "    data_levels.append(float(i))\n",
      "annual_max = data_levels    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fit data to GEV distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gev_pdf(x):\n",
      "    return genextreme.pdf(x, xi, loc=mu, scale=sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mle = genextreme.fit(sorted(annual_max), 0)\n",
      "mu = mle[1]\n",
      "sigma = mle[2]\n",
      "xi = mle[0]\n",
      "print \"The mean, sigma, and shape parameters are %s, %s, and %s, resp.\" % (mu, sigma, xi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Probability Density Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_x = min(annual_max_levels)-0.5\n",
      "max_x = max(annual_max_levels)+0.5\n",
      "x = np.linspace(min_x, max_x, num=100)\n",
      "y = [gev_pdf(z) for z in x]\n",
      "\n",
      "fig = plt.figure(figsize=(12,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "xlabel = (s[\"long_name\"] + \" - Annual max Wave Height (m)\")\n",
      "axes.set_title(\"Probability Density & Normalized Histogram\")\n",
      "axes.set_xlabel(xlabel)\n",
      "axes.plot(x, y, color='Red')\n",
      "axes.hist(annual_max_levels, bins=arange(min_x, max_x, abs((max_x-min_x)/10)), normed=1, color='Yellow')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Return Value Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(20,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "T=np.r_[1:500]\n",
      "sT = genextreme.isf(1./T, 0, mu, sigma)\n",
      "axes.semilogx(T, sT, 'r'), hold\n",
      "N=np.r_[1:len(annual_max_levels)+1]; \n",
      "Nmax=max(N);\n",
      "axes.plot(Nmax/N, sorted(annual_max_levels)[::-1], 'bo')\n",
      "title = s[\"long_name\"][0] \n",
      "axes.set_title(title)\n",
      "axes.set_xlabel('Return Period (yrs)')\n",
      "axes.set_ylabel('Return Value') \n",
      "axes.grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Compute Confidence Intervals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conf_int_scipy(x, ci=0.95):\n",
      "  low_per = 100*(1-ci)/2.\n",
      "  high_per = 100*ci + low_per\n",
      "  mn = x.mean()\n",
      "  cis = ss.scoreatpercentile(x, low_per, high_per)\n",
      "  return mn, cis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}